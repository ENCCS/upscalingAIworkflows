

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TensorFlow on a single GPU &mdash; Upscaling AI workflows  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_lesson.css?v=e9df6548" />
      <link rel="stylesheet" type="text/css" href="../../../_static/term_role_formatting.css?v=4194e21c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
      <link rel="stylesheet" type="text/css" href="../../../_static/overrides.css?v=0572569b" />

  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=187304be"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../_static/minipres.js?v=a0d29692"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script data-domain="enccs.github.io/upscalingAIworkflows" defer="defer" src="https://plausible.io/js/script.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            Upscaling AI workflows
              <img src="../../../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup/">Access to Vega</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro-container/">Introduction to Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro_docker/">Introduction to Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mang_contain/">Cleaning Up Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../create_contain/">Creating your own container images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compx_contain/">Creating More Complex Container Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../singlrty_start/">What is Singularity?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../work_contain/">Working with Singularity containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build_contain/">Building Singularity images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tf_intro/">TensorFlow on a single GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tf_mltgpus/">Distributed training in TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hvd_intro/">Intoduction to Horovod</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../train_contain/">Training Neural Networks using Containers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optional</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../containers/content/mpi_contain/">Running MPI parallel jobs using Singularity containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers/content/rep_gran/">Containers in research workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers/content/pwd_exmps/">PWD exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../namespc-cgroup/">Namespaces and cgroups</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quick-reference/">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/">Instructor’s guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">Upscaling AI workflows</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">TensorFlow on a single GPU</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/upscalingAIworkflows/blob/main/content/upscalingAIcontainer/content/tf_intro.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <figure class="align-default" id="id1">
<span id="tf-intro"></span><a class="reference internal image-reference" href="https://www.gstatic.com/devrel-devsite/prod/v93a6dcf50ad5e38e51034415df5b4a8345b5c8613f785e48818ae468dabf73c8/tensorflow/images/lockup.svg"><img alt="https://www.gstatic.com/devrel-devsite/prod/v93a6dcf50ad5e38e51034415df5b4a8345b5c8613f785e48818ae468dabf73c8/tensorflow/images/lockup.svg" src="https://www.gstatic.com/devrel-devsite/prod/v93a6dcf50ad5e38e51034415df5b4a8345b5c8613f785e48818ae468dabf73c8/tensorflow/images/lockup.svg" style="width: 40%;" />
</a>
<figcaption>
<p><span class="caption-text"><a class="reference external" href="https://www.tensorflow.org">(Image Source)</a></span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="tensorflow-on-a-single-gpu">
<h1>TensorFlow on a single GPU<a class="headerlink" href="#tensorflow-on-a-single-gpu" title="Link to this heading"></a></h1>
<p>TensorFlow is a well-known library developed primarily in Google which has been
proven to be one of the most robust, reilable, and fast libraries for deep learning
among developers. I think most of us have had some form of exposure to TensorFlow
at some point in our deep learning/machin learning journery.</p>
<p>In this section we focus on using a single GPU for training our model. It is rather
easy to transfer/port traning of the model to the GPU with minimal coding.</p>
<p>TensorFlow supports running computations on a variety of types of devices, including
CPU and GPU. They are represented with string identifiers for example:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/device:CPU:0</span></code>: The CPU of your machine.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/GPU:0</span></code>: Short-hand notation for the first GPU of your machine that is
visible to TensorFlow.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/job:localhost/replica:0/task:0/device:GPU:1</span></code>: Fully qualified name of
the second GPU of your machine that is visible to TensorFlow.</p></li>
</ul>
</div></blockquote>
<p>If a TensorFlow operation has both CPU and GPU implementations, by default,
the GPU device is prioritized when the operation is assigned. For example, <code class="docutils literal notranslate"><span class="pre">tf.matmul</span></code>
has both CPU and GPU kernels and on a system with devices <code class="docutils literal notranslate"><span class="pre">CPU:0</span></code> and <code class="docutils literal notranslate"><span class="pre">GPU:0</span></code>,
the <code class="docutils literal notranslate"><span class="pre">GPU:0</span></code> device is selected to run <code class="docutils literal notranslate"><span class="pre">tf.matmul</span></code> unless you explicitly request
to run it on another device.</p>
<p>If a TensorFlow operation has no corresponding GPU implementation, then the operation
falls back to the CPU device. For example, since <code class="docutils literal notranslate"><span class="pre">tf.cast</span></code> only has a CPU kernel,
on a system with devices <code class="docutils literal notranslate"><span class="pre">CPU:0</span></code> and <code class="docutils literal notranslate"><span class="pre">GPU:0</span></code>, the <code class="docutils literal notranslate"><span class="pre">CPU:0</span></code> device is selected
to run <code class="docutils literal notranslate"><span class="pre">tf.cast</span></code>, even if requested to run on the <code class="docutils literal notranslate"><span class="pre">GPU:0</span></code> device.</p>
<section id="get-the-physical-devices">
<h2>Get the physical devices<a class="headerlink" href="#get-the-physical-devices" title="Link to this heading"></a></h2>
<p>After booking a node with multiple GPUs, let’s check if we have TensorFlow module
loaded and if the physical GPU device is available.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Num of GPUs Available: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TensorFlow version: &quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Num<span class="w"> </span>of<span class="w"> </span>GPUs<span class="w"> </span>Available:<span class="w">  </span><span class="m">6</span>
TensorFlow<span class="w"> </span>version:<span class="w">  </span><span class="m">2</span>.5.0
</pre></div>
</div>
<p>We can see the list of all of available devices:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:CPU:0&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;CPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:0&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:1&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:2&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:3&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:4&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)</span>,
PhysicalDevice<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:5&#39;</span>,<span class="w"> </span><span class="nv">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="o">)]</span>
</pre></div>
</div>
<p>If you have GPUs, then you should see the GPU device in the above list.
We can also check specifically for the GPU or CPU devices.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;CPU&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="placement-of-calculations">
<h2>Placement of calculations<a class="headerlink" href="#placement-of-calculations" title="Link to this heading"></a></h2>
<p>TensorFlow automatically place tensor operations to physical devices which is by
default is the GPU if available. Now, let’s define a random Tensor, and check where
it is placed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">x</span><span class="o">.</span><span class="n">device</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;/job:localhost/replica:0/task:0/device:GPU:0&#39;</span>
</pre></div>
</div>
<p>The above string will end with <code class="docutils literal notranslate"><span class="pre">GPU:K</span></code> if the Tensor is placed on the K-th GPU device.
We can also check if a tensor is placed on a specific device by using <code class="docutils literal notranslate"><span class="pre">device_endswith</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Is the Tensor on CPU #0:  &quot;</span><span class="p">),</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;CPU:0&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Is the Tensor on GPU #0:  &quot;</span><span class="p">),</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;GPU:0&#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Is<span class="w"> </span>the<span class="w"> </span>Tensor<span class="w"> </span>on<span class="w"> </span>CPU<span class="w"> </span><span class="c1">#0:</span>
False

Is<span class="w"> </span>the<span class="w"> </span>Tensor<span class="w"> </span>on<span class="w"> </span>GPU<span class="w"> </span><span class="c1">#0:</span>
True
</pre></div>
</div>
</section>
<section id="determining-the-placement">
<h2>Determining the Placement<a class="headerlink" href="#determining-the-placement" title="Link to this heading"></a></h2>
<p>It is possible to force placement on specific devices, if they are available. We can view
the benefits of GPU acceleration by running some tests and placing the operations on
the CPU or GPU respectively.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="k">def</span><span class="w"> </span><span class="nf">time_matadd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">loop</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix addition (10 loops): </span><span class="si">{:0.2f}</span><span class="s2">ms&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">1000</span><span class="o">*</span><span class="n">result</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">time_matmul</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">loop</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix multiplication (10 loops): </span><span class="si">{:0.2f}</span><span class="s2">ms&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">1000</span><span class="o">*</span><span class="n">result</span><span class="p">))</span>
</pre></div>
</div>
<p>We run the above tests first on a CPU using <code class="docutils literal notranslate"><span class="pre">tf.device(&quot;CPU:0&quot;)</span></code>,
which forces the operations to be run on the CPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;On CPU:&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;CPU:0&quot;</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span>
  <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;CPU:0&quot;</span><span class="p">)</span>
  <span class="n">time_matadd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">time_matmul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>On<span class="w"> </span>CPU:
Matrix<span class="w"> </span>addition<span class="w"> </span><span class="o">(</span><span class="m">10</span><span class="w"> </span>loops<span class="o">)</span>:<span class="w"> </span><span class="m">3</span>.51ms
Matrix<span class="w"> </span>multiplication<span class="w"> </span><span class="o">(</span><span class="m">10</span><span class="w"> </span>loops<span class="o">)</span>:<span class="w"> </span><span class="m">199</span>.40ms
</pre></div>
</div>
<p>And doing the same operations on the GPU:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;On GPU:&quot;</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;GPU:0&quot;</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;GPU:0&quot;</span><span class="p">)</span>
    <span class="n">time_matadd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">time_matmul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>On<span class="w"> </span>GPU:
Matrix<span class="w"> </span>addition<span class="w"> </span><span class="o">(</span><span class="m">10</span><span class="w"> </span>loops<span class="o">)</span>:<span class="w"> </span><span class="m">0</span>.89ms
Matrix<span class="w"> </span>multiplication<span class="w"> </span><span class="o">(</span><span class="m">10</span><span class="w"> </span>loops<span class="o">)</span>:<span class="w"> </span><span class="m">22</span>.64ms
</pre></div>
</div>
<p>Note the significant time difference between running these operations on different devices.</p>
</section>
<section id="logging-device-placement">
<h2>Logging device placement<a class="headerlink" href="#logging-device-placement" title="Link to this heading"></a></h2>
<p>We can find out which devices your operations and tensors are assigned to by putting
<code class="docutils literal notranslate"><span class="pre">tf.debugging.set_log_device_placement(True)</span></code> as the first statement of your program.
Enabling device placement logging causes any Tensor allocations or operations to be printed.</p>
<div class="admonition-training-on-cpu-and-gpu exercise important admonition" id="exercise-0">
<p class="admonition-title">Training on CPU and GPU</p>
<p>You can find two neural networks for image classifier for the <cite>The Street View
House Numbers (SVHN)</cite> dataset in the github <a class="reference download internal" download="" href="../../../_downloads/74ee731ebfed19400b39072f6460b14f/SVHN_class.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">SVHN</span> <span class="pre">notebook</span></code></a>.
Try to train the model on CPU and GPU. Compare the results.</p>
<p>Can you place manually some parts on GPU and some on CPU?</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, ENCCS, and individual contributors..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>